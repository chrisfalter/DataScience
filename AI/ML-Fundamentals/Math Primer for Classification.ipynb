{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just Enough Math for Classification Models\n",
    "## A Prediction Function\n",
    "A prediction for a binary event (true vs. false) is mathematically expressed as a floating-point number between 0.0 (utterly impossible) and 1.0 (happens every time). An event with probability `0.1` is not very likely because it happens only a tenth of the time, but an event with probability `0.9`, like the election of a Democratic president in 2016, is almost certain to happen. \n",
    "\n",
    "A prediction _function_ predicts the probability `Y` of an outcome `C`, given data `X`:\n",
    "\n",
    "$\\hat{Y} = P(C | X)$\n",
    "\n",
    "A machine learning classification model is essentially a prediction function. For example, a super-simple spam classifier for emails could make keyword-based predictions, given the message body. By convention, a prediction `>= 0.5` is `True` and `< 0.5` is False, although you could set the True/False threshold higher or lower depending on the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability 'Get a loan for our low price viagra meds!' is spam = 0.75. Probably it is spam.\n",
      "Probability 'Congratulations on your promotion to staff scientist!' is spam = 0.0. Probably it is not spam.\n"
     ]
    }
   ],
   "source": [
    "# predict spam if 2 or more keywords are present in mail body\n",
    "def predict_spam(body):\n",
    "    spam_words = ['credit', 'card', 'loan', 'meds', 'viagra']\n",
    "    probability = 0.0\n",
    "    for word in spam_words:\n",
    "        if word in body:\n",
    "            probability += 0.25\n",
    "        if probability == 1.0:\n",
    "            return 1.0\n",
    "    return probability\n",
    "\n",
    "spam = \"Get a loan for our low price viagra meds!\"\n",
    "ham = \"Congratulations on your promotion to staff scientist!\"\n",
    "d = {True: \"is\", False: \"is not\"}\n",
    "\n",
    "for x in [spam, ham]:\n",
    "    p_spam = predict_spam(x)\n",
    "    is_spam = p_spam >= 0.5\n",
    "    print(f\"Probability '{x}' is spam = {p_spam}. Probably it {d[is_spam]} spam.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class prediction\n",
    "\n",
    "### A naive approach\n",
    "When an outcome can be one of several classes, a classification model makes an array of predictions. We assign one position in the array to each class; thus each element in the prediction array represents the prediction for its corresponding class.\n",
    "\n",
    "The sample code below is one way to predict the probabilities for each face when you roll a die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18026969, 0.01947524, 0.46321853, 0.72493393, 0.4202036 ,\n",
       "       0.4854271 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_die_classes(seed):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(size = (6,))\n",
    "\n",
    "predict_die_classes(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def predict_spots(class_predictions):\n",
    "    return np.argmax(class_predictions) + 1\n",
    "\n",
    "for i in range(6):\n",
    "    print(predict_spots(predict_die_classes(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with naivete\n",
    "We have a problem: the class probabilities for an event must sum to 1.0. But the sum of the array elements returned by the `predict_die_classes` function does not equal 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.293528088810396"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predict_die_classes(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The softmax solution\n",
    "One way to solve the problem would be proportionality: simply divide each prediction/element by the sum of the array. A better way is the softmax function, which makes the highest probability go toward 1.0 and the smaller probabilities go toward 0.0 when the predictions are unbounded real numbers, as they typically are in real-world machine learning models:\n",
    "\n",
    "$softmax([y_0, y_1,..., y_k]) = \\frac{[e^{y_0}, e^{y_1}, ...., e^{y_k}]}{\\sum{e^{y_n}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.98685661 -0.5530572   2.59075415  6.09211943 -0.9366135  -0.93654783]\n",
      "\n",
      "[1.57049260e-02 1.23869772e-03 2.87279915e-02 9.52640149e-01\n",
      " 8.44090392e-04 8.44145826e-04]\n"
     ]
    }
   ],
   "source": [
    "def predict_die_classes_v2(seed):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.randn(6) * 4\n",
    "\n",
    "print(predict_die_classes_v2(42))\n",
    "\n",
    "def softmax(y):\n",
    "    return np.exp(y)/np.sum(np.exp(y))\n",
    "\n",
    "print()\n",
    "print(softmax(predict_die_classes_v2(42)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(softmax(predict_die_classes_v2(42))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Prediction Accuracy with a Loss Function\n",
    "Now that we have a class prediction array is an array of probabilities that sums to 1.0, we can design a _loss function_ that measures the accuracy of the prediction. The basic idea is that the more accurate the prediction is, the lower the loss; and conversely, the less accurate the prediction, the higher the loss. Machine learning is, at its most basic, a way to gradually adjust the parameters of a model so that its loss decreases as it iteratively compares training data examples to their corresponding predictions. As the model's loss decreases, we expect (with certain caveats) its accuracy in predicting unseen examples to increase. \n",
    "\n",
    "The process for adjusting parameters is a complex topic for another day. For today, let's just see how we can measure the loss of a classification model. \n",
    "\n",
    "### Step 1: Class labels in one-hot format\n",
    "Remember that the model's prediction is simply the index of the highest probability in the prediction array. A naive way to measure loss would be to set the loss = 0.0 when the index matches the ground truth label, and set the loss = 1.0 when the index does not match the ground truth label. However, this would not be very helpful, because we want to adjust the model parameter proportionally to the error. \n",
    "\n",
    "For example, if the actual die roll is `3` and the softmax prediction array is `[0.01, 0.95, 0.01, 0.01, 0.01, 0.01]` ==> `2`, we would like to make a big adjustment to model parameters that and disfavored a `3`. \n",
    "\n",
    "If the actual die roll is `3` and the prediction array is `[0.01, 0.01, 0.465, 0.01, 0.01, 0.475]` ==> `6`, we have a different situation; the amount by which we want to adjust the parameters that disfavored a `3` is much smaller.\n",
    "\n",
    "The way forward is to put the ground truth label in _one-hot_ format. This means that the label is an array with a value of 1.0 at the index corresponding to the correct class, and zeros everywhere else. For example, a ground truth label of `3` for a die roll would be as follows in one-hot format:\n",
    "\n",
    "```\n",
    "[0,0,1,0,0,0]\n",
    "```\n",
    "\n",
    "A ground truth label of `1` would of course be:\n",
    "\n",
    "```\n",
    "[1,0,0,0,0,0]\n",
    "```\n",
    "\n",
    "By putting the label in one-hot format, we can now make an element-wise comparison between the prediction array and the one-hot ground truth array. \n",
    "\n",
    "First let's declare a one-hot function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(label, num_classes):\n",
    "    the_array = np.zeros((num_classes,))\n",
    "    the_array[label - 1] = 1.0\n",
    "    return the_array\n",
    "\n",
    "one_hot(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how it encodes the ground truth for a 3-spot roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for a 6-spot roll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_6 = one_hot(6, 6)\n",
    "label_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loss function\n",
    "A loss function gives a mathematical measurement of how well a model makes predictions. \n",
    "\n",
    "#### Naive loss function\n",
    "For our die-roll classification model, a naive loss function might be the element-wise difference between the softmax prediction array and the one-hot encoded ground truth array. Given an input condition of `x = 42`, let's start by getting the prediction array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.57049260e-02, 1.23869772e-03, 2.87279915e-02, 9.52640149e-01,\n",
       "       8.44090392e-04, 8.44145826e-04])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_array = softmax(predict_die_classes_v2(42))\n",
    "prediction_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define that naive loss function and see what it tells us when the ground truth, given condition `x = 42`, is `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.57049260e-02  1.23869772e-03  2.87279915e-02  9.52640149e-01\n",
      "  8.44090392e-04 -9.99155854e-01]\n"
     ]
    }
   ],
   "source": [
    "def naive_loss(predictions, ground_truth):\n",
    "    return predictions - ground_truth\n",
    "\n",
    "label_6 = one_hot(6, 6)\n",
    "loss_6 = naive_loss(prediction_array, label_6)\n",
    "print(loss_6) # not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose the ground truth, given condition `x = 42`, is a `4` instead. What does the loss function tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01570493  0.0012387   0.02872799 -0.04735985  0.00084409  0.00084415]\n"
     ]
    }
   ],
   "source": [
    "label_4 = one_hot(4, 6)\n",
    "loss_4 = naive_loss(prediction_array, label_4)\n",
    "print(diffs_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the loss array are much lower, so we can infer that the model did a much better job for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better: The cross-entropy loss function\n",
    "Unfortunately, the naive simple difference function does not work well for machine learning because it makes the optimization of model parameters very difficult. (See [this Quora post](https://qr.ae/TW4uPv) for an explanation.) The cross-entropy loss function (symbolized here as `J`) is much more effective for the purpose:\n",
    "\n",
    "`Let: Prediction array = P, one-hot ground truth = Y`\n",
    "\n",
    "$J(P, Y) = -\\sum{Y_i*log(P_i)}$\n",
    "\n",
    "See [this blog post](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/) for a deeper explanation of why cross-entropy is a useful construct for measuring loss. Let's see a Python definition of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(prediction, actual):\n",
    "    \"\"\" Returns the CE loss, given a prediction array and a one-hot ground truth array\"\"\"\n",
    "    return -np.sum(np.log(prediction) * actual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will recall that the model was not very accurate when ground truth was `6` under the condition of `x = 42`. What does the the cross-entropy loss function tell us about this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.077185298608924\n"
     ]
    }
   ],
   "source": [
    "loss_predicting_6 = cross_entropy_loss(prediction_array, label_6)\n",
    "print(loss_predicting_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy loss tells us that the magnitude of the loss is very high. That's exactly what we wanted. Now how does it deal with the pretty good prediction when ground truth is `4`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04851804518010041\n"
     ]
    }
   ],
   "source": [
    "loss_predicting_4 = cross_entropy_loss((prediction_array), label_4)\n",
    "print(loss_predicting_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! The magnitude of the loss is vastly smaller, reflecting the much more accurate prediction array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "##### The probability of an outcome is expressed as a real number in the range 0.0 (impossible) to 1.0 (always happens)\n",
    "##### Predictions about potential outcomes (classes) for an event are expressed as an array of probabilities.\n",
    "Each class, or outcome, has a unique position in the array.\n",
    "##### We \"normalize\" the prediction array by applying the softmax function.\n",
    "This causes the probabilities to sum to `1.0`. It also drives the most likely outcome, as predicted by the model, toward `1.0` and the others toward `0.0`.\n",
    "##### We measure how well a classification model predicts class probabilities by a loss function.\n",
    "The loss function compares the prediction array with the ground truth array, which is one-hot encoded for the purpose of the comparison. A large loss means the model is doing poorly; a small loss means the model is doing well.\n",
    "##### We typically use cross-entropy loss for machine learning classification models because it helps optimize the model's parameters more effectively than a naive loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
